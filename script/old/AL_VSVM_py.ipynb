{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#from dfply import arrange\n",
    "\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import cohen_kappa_score, make_scorer\n",
    "\n",
    "from sklearn.model_selection import BaseCrossValidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rpy2\n",
    "import rpy2.robjects as robjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path1 = \"/home/rsrg9/Documents/tunc_oz/apply_model\"\n",
    "path1 = \"D:/tunc_oz/apply_model\"\n",
    "os.chdir(path1)\n",
    "\n",
    "# Second path\n",
    "path2 = \"csv_data_r_import/cologne/scale\"\n",
    "os.chdir(path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.97333333])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "X, y = datasets.load_iris(return_X_y=True)\n",
    "X.shape, y.shape\n",
    "\n",
    "def custom_cv_2folds(X):\n",
    "    n = X.shape[0]\n",
    "    i = 1\n",
    "    while i <= 2:\n",
    "        idx = np.arange(n * (i - 1) / 2, n * i / 2, dtype=int)\n",
    "        yield idx, idx\n",
    "        i += 1\n",
    "custom_cv = custom_cv_2folds(X)\n",
    "clf = svm.SVC(kernel='linear', C=1, random_state=42)\n",
    "cross_val_score(clf, X, y, cv=custom_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object custom_cv_2folds at 0x000001E977252970>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_fit(x, y, custom_splitter=None):\n",
    "    # Expand coarse grid\n",
    "    coarse_grid = {'C': 2.0 ** np.arange(-4, 13, 2),\n",
    "                   'gamma': 2.0 ** np.arange(-5, 4, 2)}\n",
    "    \n",
    "    kappa_scorer = make_scorer(cohen_kappa_score)\n",
    "\n",
    "    # Coarse grid search\n",
    "    svm_coarse = SVC(kernel='rbf')\n",
    "    svm_coarse_cv = GridSearchCV(svm_coarse, param_grid=coarse_grid, scoring=kappa_scorer)#, cv=custom_splitter)\n",
    "    svm_coarse_cv.fit(x, y)\n",
    "    \n",
    "    # Get best coarse grid parameters\n",
    "    best_c = svm_coarse_cv.best_params_['C']\n",
    "    best_gamma = svm_coarse_cv.best_params_['gamma']\n",
    "    \n",
    "    # Define narrow grid borders\n",
    "    a_gamma = np.log2(best_gamma) - 2\n",
    "    b_gamma = np.log2(best_gamma) + 2\n",
    "    a_c = np.log2(best_c) - 2\n",
    "    b_c = np.log2(best_c) + 2\n",
    "    \n",
    "    # Expand narrow grid\n",
    "    narrow_grid = {'C': 2.0 ** np.arange(a_c, b_c, 0.5),\n",
    "                   'gamma': 2.0 ** np.arange(a_gamma, b_gamma, 0.5)}\n",
    "    \n",
    "    # Narrow grid search\n",
    "    svm_narrow = SVC(kernel='rbf')\n",
    "    svm_narrow_cv = GridSearchCV(svm_narrow, param_grid=narrow_grid, scoring=kappa_scorer)#, cv=custom_splitter)\n",
    "    svm_narrow_cv.fit(x, y)\n",
    "    \n",
    "    return svm_narrow_cv\n",
    "\n",
    "# Usage example:\n",
    "# svm_model = svm_fit(X_train, y_train, StratifiedKFold(n_splits=10, shuffle=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Euclidean Distance between two points lying in the input space\n",
    "def euc_dis(a, b):\n",
    "    temp = 0\n",
    "    for ii in range(len(a)):\n",
    "        temp += (a[ii] - b[ii])**2\n",
    "    return np.sqrt(temp)\n",
    "\n",
    "# Evaluate the distance between Virtual Support Vectors and Support Vectors lying in the input space\n",
    "def rem_extrem(org, VSV1, a):\n",
    "    distance = pd.DataFrame(index=range(len(org)), columns=['label', 'distance'])\n",
    "    distanceSVC1 = []\n",
    "    distanceSVC2 = []\n",
    "    \n",
    "    for l in range(len(org)):\n",
    "        distance.loc[l, 'label'] = str(org.iloc[l, -1])\n",
    "        distance.loc[l, 'distance'] = euc_dis(org.iloc[l, :-1], VSV1.iloc[l, :-1])\n",
    "    \n",
    "    SVClass1 = org[org['REF'] == org['REF'].unique()[0]]\n",
    "    SVClass2 = org[org['REF'] == org['REF'].unique()[1]]\n",
    "    \n",
    "    if len(SVClass1) > 0:\n",
    "        for n in range(len(SVClass1) - 1):\n",
    "            for nn in range(n, len(SVClass1) - 1):\n",
    "                distanceSVC1.append(euc_dis(SVClass1.iloc[n, :-1], SVClass1.iloc[n + nn, :-1]))\n",
    "        disClass1median = np.mean(distanceSVC1)\n",
    "        boundClass1 = disClass1median * a\n",
    "    \n",
    "    if len(SVClass2) > 0:\n",
    "        for n in range(len(SVClass2) - 1):\n",
    "            for nn in range(n, len(SVClass2) - 1):\n",
    "                distanceSVC2.append(euc_dis(SVClass2.iloc[n, :-1], SVClass2.iloc[n + nn, :-1]))\n",
    "        disClass2median = np.mean(distanceSVC2)\n",
    "        boundClass2 = disClass2median * a\n",
    "    \n",
    "    for k in range(len(org)):\n",
    "        if np.isnan(distance.loc[k, 'distance']):\n",
    "            VSV1.iloc[k, :] = np.nan\n",
    "        else:\n",
    "            if boundClass1 is not None:\n",
    "                if distance.loc[k, 'label'] == org['REF'].unique()[0]:\n",
    "                    if distance.loc[k, 'distance'] > boundClass1:\n",
    "                        VSV1.iloc[k, :] = np.nan\n",
    "            else:\n",
    "                if boundClass2 is not None:\n",
    "                    if distance.loc[k, 'label'] == org['REF'].unique()[1]:\n",
    "                        if distance.loc[k, 'distance'] > boundClass2:\n",
    "                            VSV1.iloc[k, :] = np.nan\n",
    "    return VSV1\n",
    "\n",
    "# Kernel distance between two points lying in the hyperspace\n",
    "def kern_dis(a, b, kernelfunc):\n",
    "    a = np.array(a).flatten()\n",
    "    b = np.array(b).flatten()\n",
    "    dk = np.sqrt(kernelfunc(a, a) + kernelfunc(b, b) - 2 * kernelfunc(a, b))\n",
    "    return dk\n",
    "\n",
    "# Evaluate the distance between Virtual Support Vectors and Support Vectors lying in the hyperspace\n",
    "def rem_extrem_kerneldist(org, VSV1, a, kernelfunc):\n",
    "    distance = pd.DataFrame(index=range(len(org)), columns=['label', 'distance'])\n",
    "    distanceSVC1 = []\n",
    "    distanceSVC2 = []\n",
    "    \n",
    "    for l in range(len(org)):\n",
    "        distance.loc[l, 'label'] = str(org.iloc[l, -1])\n",
    "        distance.loc[l, 'distance'] = kern_dis(org.iloc[l, :-1], VSV1.iloc[l, :-1], kernelfunc)\n",
    "    \n",
    "    SVClass1 = org[org['REF'] == org['REF'].unique()[0]]\n",
    "    SVClass2 = org[org['REF'] == org['REF'].unique()[1]]\n",
    "    \n",
    "    if len(SVClass1) > 0:\n",
    "        for n in range(len(SVClass1) - 1):\n",
    "            for nn in range(n, len(SVClass1) - 1):\n",
    "                distanceSVC1.append(kern_dis(SVClass1.iloc[n, :-1], SVClass1.iloc[n + nn, :-1], kernelfunc))\n",
    "        disClass1median = np.mean(distanceSVC1)\n",
    "        boundClass1 = disClass1median * a\n",
    "    \n",
    "    if len(SVClass2) > 0:\n",
    "        for n in range(len(SVClass2) - 1):\n",
    "            for nn in range(n, len(SVClass2) - 1):\n",
    "                distanceSVC2.append(kern_dis(SVClass2.iloc[n, :-1], SVClass2.iloc[n + nn, :-1], kernelfunc))\n",
    "        disClass2median = np.mean(distanceSVC2)\n",
    "        boundClass2 = disClass2median * a\n",
    "    \n",
    "    for k in range(len(org)):\n",
    "        if np.isnan(distance.loc[k, 'distance']):\n",
    "            VSV1.iloc[k, :] = np.nan\n",
    "        else:\n",
    "            if boundClass1 is not None:\n",
    "                if distance.loc[k, 'label'] == org['REF'].unique()[0]:\n",
    "                    if distance.loc[k, 'distance'] > boundClass1:\n",
    "                        VSV1.iloc[k, :] = np.nan\n",
    "            else:\n",
    "                if boundClass2 is not None:\n",
    "                    if distance.loc[k, 'label'] == org['REF'].unique()[1]:\n",
    "                        if distance.loc[k, 'distance'] > boundClass2:\n",
    "                            VSV1.iloc[k, :] = np.nan\n",
    "    return VSV1\n",
    "\n",
    "def pred_one(model, data_point):\n",
    "    # Extract necessary components from the SVM model\n",
    "    support_vectors = model.n_support_\n",
    "    kernel_function = model.kernel\n",
    "    coefficients = model.dual_coef_.ravel()\n",
    "    intercept = model.intercept_\n",
    "    \n",
    "    # Initialize prediction variable\n",
    "    prediction = 0\n",
    "    \n",
    "    # Iterate over each support vector\n",
    "    for j in range(len(support_vectors)):\n",
    "        # Compute kernel function value between the j-th support vector and the data point\n",
    "        kernel_value = kernel_function(data_point.reshape(1, -1), model.support_vectors_[j, :].reshape(1, -1))\n",
    "        \n",
    "        # Multiply kernel value by the corresponding coefficient and add to prediction\n",
    "        weighted_value = kernel_value * coefficients[j]\n",
    "        prediction += weighted_value\n",
    "    \n",
    "    # Subtract intercept to get the final prediction\n",
    "    final_prediction = prediction - intercept\n",
    "    \n",
    "    return final_prediction\n",
    "\n",
    "def uncertainty_dist_v2_2(org, samp):\n",
    "    distance = pd.DataFrame(columns=['control_label', 'distance'], index=range(len(samp)))\n",
    "    \n",
    "    for k in range(len(samp)):\n",
    "        distance.loc[k, 'distance'] = np.sign(pred_one(org.finalModel, samp.iloc[k, :-1])) * \\\n",
    "                                      np.where(pred_one(org.finalModel, samp.iloc[k, :-1]) > 0, 1, -1)\n",
    "    \n",
    "    # Normalize distance\n",
    "    preProc = preprocessing.MinMaxScaler()\n",
    "    preProc.fit(distance[['distance']])\n",
    "    normdistance = preProc.transform(distance[['distance']])\n",
    "    \n",
    "    samp['normdistance'] = normdistance\n",
    "    \n",
    "    return samp\n",
    "\n",
    "def alter_labels(distance_data, ref):\n",
    "    # Merge features and original labels\n",
    "    ref_added = pd.concat([distance_data, ref], axis=1)\n",
    "    # Order by most uncertain samples\n",
    "    ref_added_or = ref_added.sort_values(by='distance')\n",
    "    # Re-label most uncertain n number of samples\n",
    "    ref_added_or.iloc[:250, -1] = ref_added_or.iloc[:250, -2]\n",
    "    ref_added_or.iloc[:250, -2] = 1.0\n",
    "    # Re-order dataset by its index\n",
    "    ref_added_or['index'] = range(len(ref_added_or))\n",
    "    ref_added_reor = ref_added_or.sort_values(by='index')\n",
    "    \n",
    "    # Extract labels for prediction\n",
    "    labels = ref_added_reor.iloc[:, -5]\n",
    "    return labels\n",
    "\n",
    "def ExCsvMSD(datadase, filename=None):\n",
    "    # Convert to numpy array\n",
    "    datadase = np.array(datadase)\n",
    "    n = datadase.shape[1]\n",
    "    MSDdata = np.empty((2, n), dtype=float)\n",
    "    \n",
    "    MSDdata[0, :] = np.mean(datadase, axis=0)\n",
    "    MSDdata[1, :] = np.std(datadase, axis=0)\n",
    "    \n",
    "    MSDdata_final = np.vstack((datadase, MSDdata))\n",
    "    \n",
    "    # Export final mean and standard deviation to .csv-file\n",
    "    if filename is not None:\n",
    "        pd.DataFrame(MSDdata_final).to_csv(filename, index=False, header=False)\n",
    "    \n",
    "    return MSDdata_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputPath = \"cologne_res_100_L2-L13.csv\"\n",
    "sMax = 1000\n",
    "bound = [0.3, 0.6, 0.9]\n",
    "boundMargin = [1.5, 1.0, 0.5]\n",
    "sampleSizesPor = [40, 25, 16, 12, 10, 8, 6, 4, 3, 2, 1]\n",
    "colheader = [\"40\", \"25\", \"16\", \"12\", \"10\", \"8\", \"6\", \"4\", \"3\", \"2\", \"1\"]\n",
    "sindexSVMDATA = 36\n",
    "numFeat = 18\n",
    "eindexSVMDATA = sindexSVMDATA + numFeat - 1\n",
    "objInfoNames = [\"Lx_g_comp\", \"Lx_g_elfi\", \"Lx_g_refi\", \"Lx_g_roun\", \"Lx_g_shin\",\n",
    "                \"Lx_m_bl\", \"Lx_m_gr\", \"Lx_m_ndvi\", \"Lx_m_nir\", \"Lx_m_re\",\n",
    "                \"Lx_sd_bl\", \"Lx_sd_gr\", \"Lx_sd_ndvi\", \"Lx_sd_nir\", \"Lx_sd_re\",\n",
    "                \"Lx_t_diss\", \"Lx_t_hom\", \"Lx_t_mean\",\n",
    "                \"label\"]\n",
    "columnClass = [None] * 217 + [\"factor\", \"integer\"]\n",
    "\n",
    "# Import data\n",
    "preproc_DataPool = pd.read_csv(inputPath, header=0, sep=\";\", dtype=str, na_values=None)\n",
    "\n",
    "tmp_DataPool = preproc_DataPool.iloc[:, :-2]\n",
    "\n",
    "generalDataPool_columns = tmp_DataPool.columns\n",
    "\n",
    "converters = {col: lambda x: float(x.replace(',', '.')) for col in generalDataPool_columns}\n",
    "generalDataPool = pd.read_csv(inputPath, header=0, sep=\";\", na_values=None, converters=converters)\n",
    "\n",
    "\n",
    "generalDataPool.dropna(subset=[\"REF\"], inplace=True)  # Remove rows with missing REF values\n",
    "generalDataPool[\"REF\"] = pd.Categorical(generalDataPool[\"REF\"])\n",
    "\n",
    "# Transform to 2-Class-Case \"Bushes Trees\" VS rest\n",
    "first_label_class = generalDataPool[\"REF\"].cat.categories[0]  # Note that the first record is of class \"bushes trees\"\n",
    "generalDataPool[\"REF\"] = generalDataPool[\"REF\"].apply(lambda x: first_label_class if x == first_label_class else \"other\")\n",
    "generalDataPool[\"REF\"] = pd.Categorical(generalDataPool[\"REF\"])\n",
    "\n",
    "data = generalDataPool.iloc[:, sindexSVMDATA:eindexSVMDATA + 1]\n",
    "REF = generalDataPool.iloc[:, -1]\n",
    "data_with_label = pd.concat([data, REF], axis=1)\n",
    "data_label = data_with_label.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generalDataPool.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizedFeat['L02_G_COMP'] = normalizedFeat['L02_G_COMP'].replace(',', '.', regex=True)\n",
    "#normalizedFeat['L02_G_COMP'] = normalizedFeat['L02_G_COMP'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizedFeat['L02_G_EFIT'] = normalizedFeat['L02_G_EFIT'].apply(lambda x: pd.to_numeric(x.str.replace(',', '.'), errors='coerce'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizedFeat = generalDataPool.iloc[:, :-2]\n",
    "normalizedLabelUSE = generalDataPool.iloc[:, -2:]\n",
    "\n",
    "# Scaling\n",
    "preProc = MinMaxScaler()\n",
    "normalizedFeatBase = pd.DataFrame(preProc.fit_transform(normalizedFeat.iloc[:, sindexSVMDATA:eindexSVMDATA + 1]), columns=objInfoNames[:-1])\n",
    "\n",
    "# Apply range of basemodel to all levels\n",
    "normalizedFeat2 = pd.DataFrame(preProc.fit_transform(normalizedFeat.iloc[:, :numFeat]), columns=objInfoNames[:-1])\n",
    "normalizedFeat3 = pd.DataFrame(preProc.fit_transform(normalizedFeat.iloc[:, numFeat:(2 * numFeat)]), columns=objInfoNames[:-1])\n",
    "normalizedFeat5 = pd.DataFrame(preProc.fit_transform(normalizedFeat.iloc[:, (3 * numFeat):(4 * numFeat)]), columns=objInfoNames[:-1])\n",
    "normalizedFeat6 = pd.DataFrame(preProc.fit_transform(normalizedFeat.iloc[:, (4 * numFeat):(5 * numFeat)]), columns=objInfoNames[:-1])\n",
    "normalizedFeat7 = pd.DataFrame(preProc.fit_transform(normalizedFeat.iloc[:, (5 * numFeat):(6 * numFeat)]), columns=objInfoNames[:-1])\n",
    "normalizedFeat8 = pd.DataFrame(preProc.fit_transform(normalizedFeat.iloc[:, (6 * numFeat):(7 * numFeat)]), columns=objInfoNames[:-1])\n",
    "normalizedFeat9 = pd.DataFrame(preProc.fit_transform(normalizedFeat.iloc[:, (7 * numFeat):(8 * numFeat)]), columns=objInfoNames[:-1])\n",
    "normalizedFeat10 = pd.DataFrame(preProc.fit_transform(normalizedFeat.iloc[:, (8 * numFeat):(9 * numFeat)]), columns=objInfoNames[:-1])\n",
    "normalizedFeat11 = pd.DataFrame(preProc.fit_transform(normalizedFeat.iloc[:, (9 * numFeat):(10 * numFeat)]), columns=objInfoNames[:-1])\n",
    "\n",
    "# Recombine normalized sets to one data frame\n",
    "normalizedDataPoolAllLev = pd.concat([normalizedFeat2, normalizedFeat3, normalizedFeatBase, normalizedFeat5,\n",
    "                                      normalizedFeat6, normalizedFeat7, normalizedFeat8, normalizedFeat9,\n",
    "                                      normalizedFeat10, normalizedFeat11, normalizedLabelUSE], axis=1)\n",
    "\n",
    "# Remove used temporary variables\n",
    "del normalizedFeat, normalizedFeat2, normalizedFeat3, normalizedFeatBase, normalizedFeat5, normalizedFeat6\n",
    "del normalizedFeat7, normalizedFeat8, normalizedFeat9, normalizedFeat10, normalizedFeat11\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into test, train, and validate data\n",
    "trainDataPoolAllLev, testDataAllLev, validateDataAllLev = [df for _, df in normalizedDataPoolAllLev.groupby('USE')]\n",
    "trainDataPoolAllLev = trainDataPoolAllLev.iloc[:, :-1]\n",
    "testDataAllLev = testDataAllLev.iloc[:, :-1]\n",
    "validateFeatAllLev = validateDataAllLev.iloc[:, :-2]\n",
    "validateLabels = validateDataAllLev.iloc[:, -2]\n",
    "\n",
    "# Order train data pool by class label in alphabetical order\n",
    "trainDataPoolAllLev = trainDataPoolAllLev.sort_values(by=trainDataPoolAllLev.columns[-1])\n",
    "\n",
    "# Current training data-set, updated (refreshed) after each iteration\n",
    "trainDataCur = trainDataPoolAllLev.copy()\n",
    "testDataCur = testDataAllLev.copy()\n",
    "\n",
    "# Set randomized seed for the random sampling procedure\n",
    "seed = 5\n",
    "\n",
    "# Initial seed value for randomized sampling\n",
    "seed += np.random.randint(1, 101)\n",
    "\n",
    "# Definition of apriori-probabilities\n",
    "pA = pB = pC = pD = pE = pF = 1 / 6\n",
    "\n",
    "# Definition of training sample set sizes S [% of max. sample size]\n",
    "sCur = sMax * (sampleSizesPor[0] / 100)\n",
    "# Definition of sample shares\n",
    "nA, nB, nC, nD, nE, nF = [round(sCur * p) for p in [pA, pB, pC, pD, pE, pF]]\n",
    "shares = np.array([nA, nB, nC, nD, nE, nF])\n",
    "\n",
    "# Set randomized seed for the random sampling procedure\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#validateDataAllLev.columns[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stratSamp = trainDataCur.groupby('REF', observed=False)[trainDataCur.columns].apply(lambda x: x.sample(67, replace=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Lx_g_comp', 'Lx_g_elfi', 'Lx_g_refi', 'Lx_g_roun', 'Lx_g_shin',\n",
       "       'Lx_m_bl', 'Lx_m_gr', 'Lx_m_ndvi', 'Lx_m_nir', 'Lx_m_re',\n",
       "       ...\n",
       "       'Lx_sd_bl', 'Lx_sd_gr', 'Lx_sd_ndvi', 'Lx_sd_nir', 'Lx_sd_re',\n",
       "       'Lx_t_diss', 'Lx_t_hom', 'Lx_t_mean', 'REF', 'ID_unit'],\n",
       "      dtype='object', length=182)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stratSamp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sampling function\n",
    "def sample_within_group(group):\n",
    "    # Add the original IDs as a new column\n",
    "    group['ID_unit'] = group.index\n",
    "    \n",
    "    # Perform sampling within the group\n",
    "    sampled_group = group.sample(min(len(group), 67), replace=False)\n",
    "    \n",
    "    return sampled_group\n",
    "\n",
    "# Apply the sampling function to each group\n",
    "stratSamp = trainDataCur.groupby('REF', observed=False).apply(sample_within_group)\n",
    "\n",
    "# Reset the index to obtain a flat DataFrame with the original IDs preserved\n",
    "stratSamp.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Get samples of trainDataCur and set trainDataCur new\n",
    "trainDataCurRemaining = trainDataCur.drop(stratSamp[\"ID_unit\"])\n",
    "\n",
    "# Split test feat from test label for later join with trainData\n",
    "trainFeat = stratSamp.iloc[:, :len(trainDataPoolAllLev.columns)-1]\n",
    "trainLabels = stratSamp.iloc[:, len(trainDataPoolAllLev.columns)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(trainDataPoolAllLev.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Lx_g_comp', 'Lx_g_elfi', 'Lx_g_refi', 'Lx_g_roun', 'Lx_g_shin',\n",
       "       'Lx_m_bl', 'Lx_m_gr', 'Lx_m_ndvi', 'Lx_m_nir', 'Lx_m_re',\n",
       "       ...\n",
       "       'Lx_m_nir', 'Lx_m_re', 'Lx_sd_bl', 'Lx_sd_gr', 'Lx_sd_ndvi',\n",
       "       'Lx_sd_nir', 'Lx_sd_re', 'Lx_t_diss', 'Lx_t_hom', 'Lx_t_mean'],\n",
       "      dtype='object', length=180)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainFeat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'REF'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stratSamp.columns[len(trainDataPoolAllLev.columns)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stratSamp = trainDataCur.groupby('REF',observed=False)\n",
    "#stratSamp = stratSamp.apply(lambda x: x.sample(67, replace=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of sampling configuration (strata: random sampling without replacement)\n",
    "#stratSamp = trainDataCur.groupby('REF').apply(lambda x: x.sample(shares, replace=False)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainDataCur.columns[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stratSamp.iloc[:,181]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stratSamp[\"ID_unit\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainFeat.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "181"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainDataCur.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSplitter(BaseCrossValidator):\n",
    "    def __init__(self, index_train):\n",
    "        self.index_train = index_train\n",
    "\n",
    "    def split(self, X, y=None, groups=None):\n",
    "        test_indices = np.setdiff1d(np.arange(len(X)), self.index_train)\n",
    "        yield self.index_train, test_indices\n",
    "\n",
    "class CustomSplitter(BaseCrossValidator):\n",
    "    def __init__(self, index_train):\n",
    "        self.index_train = index_train\n",
    "\n",
    "    def split(self, X, y=None, groups=None):\n",
    "        test_indices = np.setdiff1d(np.arange(len(X)), self.index_train)\n",
    "        yield self.index_train, test_indices\n",
    "\n",
    "    def get_n_splits(self, X=None, y=None, groups=None):\n",
    "        return 1  # Since you're doing a single split, return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Subset for each outer iteration test data to speed up computing\n",
    "testDataCur = testDataCur.sort_values(by=testDataCur.columns[-1])\n",
    "# Apply the sampling function to each group\n",
    "stratSamp = testDataCur.groupby('REF', observed=False).apply(sample_within_group)\n",
    "\n",
    "# Split test feat from test label for later join with trainData\n",
    "testFeat = stratSamp.iloc[:, :len(testDataCur.columns)-1]\n",
    "testLabels = stratSamp.iloc[:, len(testDataCur.columns)-1]\n",
    "\n",
    "# Subset on base level\n",
    "testFeatsub = testFeat.iloc[:, sindexSVMDATA:eindexSVMDATA + 1]\n",
    "\n",
    "# TrainData index to split between train and test in svmFit\n",
    "countTrainData = trainFeat.shape[0]\n",
    "indexTrainData = [list(range(countTrainData))]\n",
    "\n",
    "# SVM base for invariants\n",
    "\n",
    "# Subset on L_4\n",
    "trainFeat = trainFeat.iloc[:, sindexSVMDATA:eindexSVMDATA + 1]\n",
    "\n",
    "# Join train and test data (separable through indexTrainData in svmFit)\n",
    "tuneFeat = pd.concat([trainFeat, testFeatsub], axis=0)\n",
    "tuneLabel = np.concatenate((trainLabels.values, testLabels.values))\n",
    "\n",
    "validateFeatsub = validateFeatAllLev.iloc[:, sindexSVMDATA:eindexSVMDATA+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(range(countTrainData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Lx_g_comp', 'Lx_g_elfi', 'Lx_g_refi', 'Lx_g_roun', 'Lx_g_shin',\n",
       "       'Lx_m_bl', 'Lx_m_gr', 'Lx_m_ndvi', 'Lx_m_nir', 'Lx_m_re', 'Lx_sd_bl',\n",
       "       'Lx_sd_gr', 'Lx_sd_ndvi', 'Lx_sd_nir', 'Lx_sd_re', 'Lx_t_diss',\n",
       "       'Lx_t_hom', 'Lx_t_mean'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainFeat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nAll the 225 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n225 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\Utente\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\Utente\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\svm\\_base.py\", line 192, in fit\n    X, y = self._validate_data(\n  File \"C:\\Users\\Utente\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py\", line 584, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"C:\\Users\\Utente\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 1106, in check_X_y\n    X = check_array(\n  File \"C:\\Users\\Utente\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 921, in check_array\n    _assert_all_finite(\n  File \"C:\\Users\\Utente\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 161, in _assert_all_finite\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nSVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m custom_splitter \u001b[38;5;241m=\u001b[39m CustomSplitter(indexTrainData)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# SVM parameter tuning\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m svm_model\u001b[38;5;241m=\u001b[39m\u001b[43msvm_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtuneFeat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtuneLabel\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[14], line 11\u001b[0m, in \u001b[0;36msvm_fit\u001b[1;34m(x, y, custom_splitter)\u001b[0m\n\u001b[0;32m      9\u001b[0m svm_coarse \u001b[38;5;241m=\u001b[39m SVC(kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrbf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     10\u001b[0m svm_coarse_cv \u001b[38;5;241m=\u001b[39m GridSearchCV(svm_coarse, param_grid\u001b[38;5;241m=\u001b[39mcoarse_grid, scoring\u001b[38;5;241m=\u001b[39mkappa_scorer)\u001b[38;5;66;03m#, cv=custom_splitter)\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[43msvm_coarse_cv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Get best coarse grid parameters\u001b[39;00m\n\u001b[0;32m     14\u001b[0m best_c \u001b[38;5;241m=\u001b[39m svm_coarse_cv\u001b[38;5;241m.\u001b[39mbest_params_[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1387\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1388\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_search.py:851\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    844\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[0;32m    845\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    846\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    847\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    848\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[0;32m    849\u001b[0m     )\n\u001b[1;32m--> 851\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[0;32m    855\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[0;32m    856\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py:367\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    361\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    362\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    363\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    364\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    365\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    366\u001b[0m     )\n\u001b[1;32m--> 367\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    370\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    371\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    372\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    377\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 225 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n225 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\Utente\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\Utente\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\svm\\_base.py\", line 192, in fit\n    X, y = self._validate_data(\n  File \"C:\\Users\\Utente\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py\", line 584, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"C:\\Users\\Utente\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 1106, in check_X_y\n    X = check_array(\n  File \"C:\\Users\\Utente\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 921, in check_array\n    _assert_all_finite(\n  File \"C:\\Users\\Utente\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 161, in _assert_all_finite\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nSVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n"
     ]
    }
   ],
   "source": [
    "countTrainData = trainFeat.shape[0]\n",
    "indexTrainData = np.array(range(countTrainData))\n",
    "\n",
    "# SVM base for invariants\n",
    "\n",
    "# Subset on L_4\n",
    "trainFeat = trainFeat.iloc[:, sindexSVMDATA:eindexSVMDATA + 1]\n",
    "\n",
    "# Join train and test data (separable through indexTrainData in svmFit)\n",
    "tuneFeat = pd.concat([trainFeat, testFeatsub], axis=0)\n",
    "tuneLabel = np.concatenate((trainLabels.values, testLabels.values))\n",
    "\n",
    "custom_splitter = CustomSplitter(indexTrainData)\n",
    "\n",
    "# SVM parameter tuning\n",
    "svm_model=svm_fit(tuneFeat, tuneLabel)#, custom_splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(268, 18)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuneFeat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM parameter tuning\n",
    "svm_model=svm_fit(tuneFeat, tuneLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bushes_trees    67\n",
       "other           67\n",
       "Name: REF, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainLabels.unique()\n",
    "trainLabels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.848417300936329\n"
     ]
    }
   ],
   "source": [
    "# Predict labels of test data\n",
    "predLabelsSVM = svm_model.predict(validateFeatsub)\n",
    "\n",
    "# Accuracy assessment\n",
    "accSVM = accuracy_score(validateLabels, predLabelsSVM)\n",
    "print(accSVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(268, 18)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuneFeat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                  0.075430\n",
       "1                  0.091789\n",
       "2                  0.090829\n",
       "3                  0.109521\n",
       "4                  0.103880\n",
       "                     ...   \n",
       "(other, 432248)    0.204029\n",
       "(other, 556566)    0.128527\n",
       "(other, 371635)    0.130255\n",
       "(other, 539219)    0.115283\n",
       "(other, 433992)    0.032179\n",
       "Name: Lx_g_comp, Length: 268, dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuneFeat.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utente\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 2 features, but SVC is expecting 18 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m xy \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack([XX\u001b[38;5;241m.\u001b[39mravel(), YY\u001b[38;5;241m.\u001b[39mravel()])\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m#evaluate the SVM value for the positive class\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m Z \u001b[38;5;241m=\u001b[39m \u001b[43msvm_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_estimator_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxy\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreshape(XX\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# plot decision boundary (w^Tx =  0) and margins (w^Tx = 1 and w^Tx = -1)\u001b[39;00m\n\u001b[0;32m     20\u001b[0m ax\u001b[38;5;241m.\u001b[39mcontour(XX, YY, Z, colors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m'\u001b[39m, levels\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m], alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m,\n\u001b[0;32m     21\u001b[0m            linestyles\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\svm\\_base.py:785\u001b[0m, in \u001b[0;36mBaseSVC.decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    758\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecision_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    759\u001b[0m     \u001b[38;5;124;03m\"\"\"Evaluate the decision function for the samples in X.\u001b[39;00m\n\u001b[0;32m    760\u001b[0m \n\u001b[0;32m    761\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    783\u001b[0m \u001b[38;5;124;03m    transformation of ovo decision function.\u001b[39;00m\n\u001b[0;32m    784\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 785\u001b[0m     dec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    786\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_function_shape \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124movr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    787\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _ovr_decision_function(dec \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39mdec, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\svm\\_base.py:534\u001b[0m, in \u001b[0;36mBaseLibSVM._decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    520\u001b[0m \u001b[38;5;124;03m\"\"\"Evaluates the decision function for the samples in X.\u001b[39;00m\n\u001b[0;32m    521\u001b[0m \n\u001b[0;32m    522\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    530\u001b[0m \u001b[38;5;124;03m    in the model.\u001b[39;00m\n\u001b[0;32m    531\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    532\u001b[0m \u001b[38;5;66;03m# NOTE: _validate_for_predict contains check for is_fitted\u001b[39;00m\n\u001b[0;32m    533\u001b[0m \u001b[38;5;66;03m# hence must be placed before any other attributes are used.\u001b[39;00m\n\u001b[1;32m--> 534\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_for_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    535\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_kernel(X)\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\svm\\_base.py:613\u001b[0m, in \u001b[0;36mBaseLibSVM._validate_for_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    610\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    612\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m callable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel):\n\u001b[1;32m--> 613\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    614\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    615\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    616\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    617\u001b[0m \u001b[43m        \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    618\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    619\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    620\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sp\u001b[38;5;241m.\u001b[39misspmatrix(X):\n\u001b[0;32m    623\u001b[0m     X \u001b[38;5;241m=\u001b[39m sp\u001b[38;5;241m.\u001b[39mcsr_matrix(X)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py:588\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    585\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    587\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 588\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    590\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py:389\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 389\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    390\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    391\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    392\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 2 features, but SVC is expecting 18 features as input."
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.figure(figsize=(12,7))\n",
    "\n",
    "plt.scatter(tuneFeat.iloc[:, 0], tuneFeat.iloc[:, 1], s=30, cmap=plt.cm.Paired)\n",
    "\n",
    "# plot the decision function\n",
    "ax = plt.gca()\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "\n",
    "# create grid to evaluate model\n",
    "xx = np.linspace(xlim[0], xlim[1], 30)\n",
    "yy = np.linspace(ylim[0], ylim[1], 30)\n",
    "YY, XX = np.meshgrid(yy, xx)\n",
    "xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "#evaluate the SVM value for the positive class\n",
    "Z = svm_model.best_estimator_.decision_function(xy).reshape(XX.shape)\n",
    "\n",
    "# plot decision boundary (w^Tx =  0) and margins (w^Tx = 1 and w^Tx = -1)\n",
    "ax.contour(XX, YY, Z, colors='k', levels=[-1, 0, 1], alpha=0.5,\n",
    "           linestyles=['--', '-', '--'])\n",
    "# plot support vectors\n",
    "ax.scatter(svm_model.best_estimator_.support_vectors_[:, 0], svm_model.best_estimator_.support_vectors_[:, 1], s=100,\n",
    "           linewidth=1, facecolors='none', edgecolors='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(181,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trainDataCur.columns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "other           357365\n",
       "bushes_trees     48420\n",
       "Name: REF, dtype: int64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDataCur['REF'].unique()\n",
    "trainDataCur['REF'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_model.n_features_in_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bushes_trees', 'other'], dtype=object)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_model.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.11770877, 0.263158  , 0.61822079, 0.44276951, 0.14035688,\n",
       "        0.02920971, 0.0208755 , 0.55691075, 0.06458741, 0.0222087 ,\n",
       "        0.06751957, 0.05327685, 0.17553671, 0.07652946, 0.05125174,\n",
       "        0.18771871, 0.03578111, 0.79301248],\n",
       "       [0.08841473, 0.675841  , 0.82627553, 0.21814325, 0.13382892,\n",
       "        0.02696745, 0.01792254, 0.4641897 , 0.04431946, 0.02005523,\n",
       "        0.03643325, 0.02949871, 0.30568572, 0.08655693, 0.02822726,\n",
       "        0.12758109, 0.04270372, 0.81109333],\n",
       "       [0.04809533, 0.861538  , 0.89016515, 0.08527873, 0.12648156,\n",
       "        0.03207706, 0.02740113, 0.51226972, 0.06290198, 0.02909166,\n",
       "        0.04648648, 0.04678275, 0.59508436, 0.15669978, 0.05465299,\n",
       "        0.10566308, 0.06175637, 0.79804385],\n",
       "       [0.20875686, 0.        , 0.41692503, 0.47196826, 0.29781484,\n",
       "        0.02770935, 0.02053573, 0.51643706, 0.05501459, 0.02121302,\n",
       "        0.03990251, 0.03671958, 0.24703117, 0.08141916, 0.02936107,\n",
       "        0.17569506, 0.02934755, 0.80734324]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_model.best_estimator_.support_vectors_[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2,   9,  14,  15,  18,  19,  23,  27,  28,  29,  30,  38,  39,\n",
       "        51,  59,  60,  64,  68,  72,  73,  75,  78,  84,  97,  99, 103,\n",
       "       111, 112, 114, 115, 117, 119, 121, 129, 131])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lx_g_comp</th>\n",
       "      <th>Lx_g_elfi</th>\n",
       "      <th>Lx_g_refi</th>\n",
       "      <th>Lx_g_roun</th>\n",
       "      <th>Lx_g_shin</th>\n",
       "      <th>Lx_m_bl</th>\n",
       "      <th>Lx_m_gr</th>\n",
       "      <th>Lx_m_ndvi</th>\n",
       "      <th>Lx_m_nir</th>\n",
       "      <th>Lx_m_re</th>\n",
       "      <th>Lx_sd_bl</th>\n",
       "      <th>Lx_sd_gr</th>\n",
       "      <th>Lx_sd_ndvi</th>\n",
       "      <th>Lx_sd_nir</th>\n",
       "      <th>Lx_sd_re</th>\n",
       "      <th>Lx_t_diss</th>\n",
       "      <th>Lx_t_hom</th>\n",
       "      <th>Lx_t_mean</th>\n",
       "      <th>REF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>141566</th>\n",
       "      <td>0.068239</td>\n",
       "      <td>0.805668</td>\n",
       "      <td>0.873817</td>\n",
       "      <td>0.141781</td>\n",
       "      <td>0.092888</td>\n",
       "      <td>0.033785</td>\n",
       "      <td>0.032189</td>\n",
       "      <td>0.620288</td>\n",
       "      <td>0.100116</td>\n",
       "      <td>0.036525</td>\n",
       "      <td>0.040698</td>\n",
       "      <td>0.037860</td>\n",
       "      <td>0.405775</td>\n",
       "      <td>0.165309</td>\n",
       "      <td>0.044026</td>\n",
       "      <td>0.090419</td>\n",
       "      <td>0.052963</td>\n",
       "      <td>0.796689</td>\n",
       "      <td>bushes_trees</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35439</th>\n",
       "      <td>0.094363</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>0.789575</td>\n",
       "      <td>0.273995</td>\n",
       "      <td>0.186283</td>\n",
       "      <td>0.029562</td>\n",
       "      <td>0.038956</td>\n",
       "      <td>0.658483</td>\n",
       "      <td>0.126350</td>\n",
       "      <td>0.045296</td>\n",
       "      <td>0.087441</td>\n",
       "      <td>0.108569</td>\n",
       "      <td>0.624496</td>\n",
       "      <td>0.336826</td>\n",
       "      <td>0.159947</td>\n",
       "      <td>0.146974</td>\n",
       "      <td>0.050292</td>\n",
       "      <td>0.826420</td>\n",
       "      <td>bushes_trees</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101611</th>\n",
       "      <td>0.073022</td>\n",
       "      <td>0.670330</td>\n",
       "      <td>0.798266</td>\n",
       "      <td>0.201985</td>\n",
       "      <td>0.077653</td>\n",
       "      <td>0.021294</td>\n",
       "      <td>0.014574</td>\n",
       "      <td>0.631935</td>\n",
       "      <td>0.061670</td>\n",
       "      <td>0.007359</td>\n",
       "      <td>0.026509</td>\n",
       "      <td>0.022434</td>\n",
       "      <td>0.316412</td>\n",
       "      <td>0.119451</td>\n",
       "      <td>0.020073</td>\n",
       "      <td>0.098026</td>\n",
       "      <td>0.060738</td>\n",
       "      <td>0.803718</td>\n",
       "      <td>bushes_trees</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101610</th>\n",
       "      <td>0.052193</td>\n",
       "      <td>0.707317</td>\n",
       "      <td>0.819672</td>\n",
       "      <td>0.142156</td>\n",
       "      <td>0.049890</td>\n",
       "      <td>0.033915</td>\n",
       "      <td>0.035445</td>\n",
       "      <td>0.678320</td>\n",
       "      <td>0.109000</td>\n",
       "      <td>0.029649</td>\n",
       "      <td>0.026247</td>\n",
       "      <td>0.020902</td>\n",
       "      <td>0.091693</td>\n",
       "      <td>0.051384</td>\n",
       "      <td>0.018004</td>\n",
       "      <td>0.213381</td>\n",
       "      <td>0.016879</td>\n",
       "      <td>0.770114</td>\n",
       "      <td>bushes_trees</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Lx_g_comp  Lx_g_elfi  Lx_g_refi  Lx_g_roun  Lx_g_shin   Lx_m_bl  \\\n",
       "141566   0.068239   0.805668   0.873817   0.141781   0.092888  0.033785   \n",
       "35439    0.094363   0.594595   0.789575   0.273995   0.186283  0.029562   \n",
       "101611   0.073022   0.670330   0.798266   0.201985   0.077653  0.021294   \n",
       "101610   0.052193   0.707317   0.819672   0.142156   0.049890  0.033915   \n",
       "\n",
       "         Lx_m_gr  Lx_m_ndvi  Lx_m_nir   Lx_m_re  Lx_sd_bl  Lx_sd_gr  \\\n",
       "141566  0.032189   0.620288  0.100116  0.036525  0.040698  0.037860   \n",
       "35439   0.038956   0.658483  0.126350  0.045296  0.087441  0.108569   \n",
       "101611  0.014574   0.631935  0.061670  0.007359  0.026509  0.022434   \n",
       "101610  0.035445   0.678320  0.109000  0.029649  0.026247  0.020902   \n",
       "\n",
       "        Lx_sd_ndvi  Lx_sd_nir  Lx_sd_re  Lx_t_diss  Lx_t_hom  Lx_t_mean  \\\n",
       "141566    0.405775   0.165309  0.044026   0.090419  0.052963   0.796689   \n",
       "35439     0.624496   0.336826  0.159947   0.146974  0.050292   0.826420   \n",
       "101611    0.316412   0.119451  0.020073   0.098026  0.060738   0.803718   \n",
       "101610    0.091693   0.051384  0.018004   0.213381  0.016879   0.770114   \n",
       "\n",
       "                 REF  \n",
       "141566  bushes_trees  \n",
       "35439   bushes_trees  \n",
       "101611  bushes_trees  \n",
       "101610  bushes_trees  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDataCur.iloc[SVindex, list(range(sindexSVMDATA,eindexSVMDATA+1))+[-1]][:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lx_g_comp</th>\n",
       "      <th>Lx_g_elfi</th>\n",
       "      <th>Lx_g_refi</th>\n",
       "      <th>Lx_g_roun</th>\n",
       "      <th>Lx_g_shin</th>\n",
       "      <th>Lx_m_bl</th>\n",
       "      <th>Lx_m_gr</th>\n",
       "      <th>Lx_m_ndvi</th>\n",
       "      <th>Lx_m_nir</th>\n",
       "      <th>Lx_m_re</th>\n",
       "      <th>...</th>\n",
       "      <th>Lx_m_re</th>\n",
       "      <th>Lx_sd_bl</th>\n",
       "      <th>Lx_sd_gr</th>\n",
       "      <th>Lx_sd_ndvi</th>\n",
       "      <th>Lx_sd_nir</th>\n",
       "      <th>Lx_sd_re</th>\n",
       "      <th>Lx_t_diss</th>\n",
       "      <th>Lx_t_hom</th>\n",
       "      <th>Lx_t_mean</th>\n",
       "      <th>REF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>109760</th>\n",
       "      <td>0.171857</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.713605</td>\n",
       "      <td>0.238544</td>\n",
       "      <td>0.152226</td>\n",
       "      <td>0.034789</td>\n",
       "      <td>0.036164</td>\n",
       "      <td>0.453214</td>\n",
       "      <td>0.061155</td>\n",
       "      <td>0.049238</td>\n",
       "      <td>...</td>\n",
       "      <td>0.139337</td>\n",
       "      <td>0.038537</td>\n",
       "      <td>0.026021</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.044961</td>\n",
       "      <td>0.017197</td>\n",
       "      <td>0.033769</td>\n",
       "      <td>0.648476</td>\n",
       "      <td>0.135342</td>\n",
       "      <td>bushes_trees</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141565</th>\n",
       "      <td>0.081891</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.838557</td>\n",
       "      <td>0.131868</td>\n",
       "      <td>0.097356</td>\n",
       "      <td>0.033760</td>\n",
       "      <td>0.037295</td>\n",
       "      <td>0.722255</td>\n",
       "      <td>0.123907</td>\n",
       "      <td>0.044875</td>\n",
       "      <td>...</td>\n",
       "      <td>0.119707</td>\n",
       "      <td>0.023619</td>\n",
       "      <td>0.016966</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.068199</td>\n",
       "      <td>0.015982</td>\n",
       "      <td>0.028416</td>\n",
       "      <td>0.689078</td>\n",
       "      <td>0.203255</td>\n",
       "      <td>bushes_trees</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141566</th>\n",
       "      <td>0.081891</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.838557</td>\n",
       "      <td>0.131868</td>\n",
       "      <td>0.097356</td>\n",
       "      <td>0.033760</td>\n",
       "      <td>0.037295</td>\n",
       "      <td>0.722255</td>\n",
       "      <td>0.123907</td>\n",
       "      <td>0.044875</td>\n",
       "      <td>...</td>\n",
       "      <td>0.119707</td>\n",
       "      <td>0.023619</td>\n",
       "      <td>0.016966</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.068199</td>\n",
       "      <td>0.015982</td>\n",
       "      <td>0.028416</td>\n",
       "      <td>0.689078</td>\n",
       "      <td>0.203255</td>\n",
       "      <td>bushes_trees</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101618</th>\n",
       "      <td>0.292604</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.477876</td>\n",
       "      <td>0.597481</td>\n",
       "      <td>0.375123</td>\n",
       "      <td>0.030327</td>\n",
       "      <td>0.031084</td>\n",
       "      <td>0.709437</td>\n",
       "      <td>0.096326</td>\n",
       "      <td>0.031764</td>\n",
       "      <td>...</td>\n",
       "      <td>0.119707</td>\n",
       "      <td>0.023619</td>\n",
       "      <td>0.016966</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.068199</td>\n",
       "      <td>0.015982</td>\n",
       "      <td>0.028416</td>\n",
       "      <td>0.689078</td>\n",
       "      <td>0.203255</td>\n",
       "      <td>bushes_trees</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows  181 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Lx_g_comp  Lx_g_elfi  Lx_g_refi  Lx_g_roun  Lx_g_shin   Lx_m_bl  \\\n",
       "109760   0.171857   0.666667   0.713605   0.238544   0.152226  0.034789   \n",
       "141565   0.081891   0.650000   0.838557   0.131868   0.097356  0.033760   \n",
       "141566   0.081891   0.650000   0.838557   0.131868   0.097356  0.033760   \n",
       "101618   0.292604   0.037037   0.477876   0.597481   0.375123  0.030327   \n",
       "\n",
       "         Lx_m_gr  Lx_m_ndvi  Lx_m_nir   Lx_m_re  ...   Lx_m_re  Lx_sd_bl  \\\n",
       "109760  0.036164   0.453214  0.061155  0.049238  ...  0.139337  0.038537   \n",
       "141565  0.037295   0.722255  0.123907  0.044875  ...  0.119707  0.023619   \n",
       "141566  0.037295   0.722255  0.123907  0.044875  ...  0.119707  0.023619   \n",
       "101618  0.031084   0.709437  0.096326  0.031764  ...  0.119707  0.023619   \n",
       "\n",
       "        Lx_sd_gr  Lx_sd_ndvi  Lx_sd_nir  Lx_sd_re  Lx_t_diss  Lx_t_hom  \\\n",
       "109760  0.026021    0.000079   0.044961  0.017197   0.033769  0.648476   \n",
       "141565  0.016966    0.000091   0.068199  0.015982   0.028416  0.689078   \n",
       "141566  0.016966    0.000091   0.068199  0.015982   0.028416  0.689078   \n",
       "101618  0.016966    0.000091   0.068199  0.015982   0.028416  0.689078   \n",
       "\n",
       "        Lx_t_mean           REF  \n",
       "109760   0.135342  bushes_trees  \n",
       "141565   0.203255  bushes_trees  \n",
       "141566   0.203255  bushes_trees  \n",
       "101618   0.203255  bushes_trees  \n",
       "\n",
       "[4 rows x 181 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDataCur[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82,)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_model.best_estimator_.support_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35, 19)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVtotal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bushes_trees    217\n",
       "other             0\n",
       "Name: REF, dtype: int64"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDataCur.iloc[svm_model.best_estimator_.support_, -1].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   2,   3,   4,   6,   8,   9,  10,  11,  12,  13,  14,  15,\n",
       "        16,  17,  18,  19,  21,  22,  23,  24,  25,  26,  27,  28,  29,\n",
       "        31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  42,  43,  44,\n",
       "        45,  46,  47,  48,  49,  50,  52,  53,  54,  55,  58,  59,  60,\n",
       "        62,  63,  65,  66, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
       "       143, 144, 145, 146, 147, 148, 149, 150, 152, 153, 155, 156, 157,\n",
       "       158, 159, 160, 161, 163, 164, 165, 166, 168, 169, 170, 171, 172,\n",
       "       174, 176, 177, 178, 180, 181, 182, 189, 190, 192, 193, 194, 195,\n",
       "       196, 197, 199, 200,  67,  68,  70,  71,  72,  73,  75,  76,  77,\n",
       "        78,  79,  80,  81,  82,  83,  85,  86,  87,  89,  90,  91,  92,\n",
       "        93,  94,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 108,\n",
       "       109, 112, 113, 118, 119, 120, 121, 123, 125, 126, 127, 128, 129,\n",
       "       130, 131, 132, 133, 201, 202, 204, 205, 206, 208, 209, 210, 211,\n",
       "       212, 213, 214, 215, 217, 218, 219, 221, 222, 223, 224, 225, 226,\n",
       "       227, 228, 229, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
       "       242, 243, 244, 245, 246, 247, 248, 250, 251, 252, 253, 254, 255,\n",
       "       256, 258, 260, 261, 263, 264, 265, 266, 267])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_model.best_estimator_.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VSVM on all Level SV\n",
    "SVindex = svm_model.best_estimator_.support_  # Indices of support vectors\n",
    "SVtotal = trainDataCur.iloc[SVindex, list(range(sindexSVMDATA,eindexSVMDATA+1))+[-1]].reset_index(drop=True)  # Get support vectors\n",
    "\n",
    "SVL2 = trainDataCur.iloc[SVindex, list(range(sindexSVMDATA - 2 * numFeat,sindexSVMDATA - numFeat))+[-1] ].reset_index(drop=True)\n",
    "SVL3 = trainDataCur.iloc[SVindex, list(range(sindexSVMDATA - numFeat,sindexSVMDATA))+[-1] ].reset_index(drop=True)\n",
    "\n",
    "SVL5 = trainDataCur.iloc[SVindex, list(range(sindexSVMDATA + numFeat,sindexSVMDATA + 2 * numFeat))+[-1] ].reset_index(drop=True)\n",
    "SVL6 = trainDataCur.iloc[SVindex, list(range(sindexSVMDATA + 2 * numFeat,sindexSVMDATA + 3 * numFeat))+[-1] ].reset_index(drop=True)\n",
    "SVL7 = trainDataCur.iloc[SVindex, list(range(sindexSVMDATA + 3 * numFeat,sindexSVMDATA + 4 * numFeat))+[-1] ].reset_index(drop=True)\n",
    "SVL8 = trainDataCur.iloc[SVindex, list(range(sindexSVMDATA + 4 * numFeat,sindexSVMDATA + 5 * numFeat))+[-1] ].reset_index(drop=True)\n",
    "SVL9 = trainDataCur.iloc[SVindex, list(range(sindexSVMDATA + 5 * numFeat,sindexSVMDATA + 6 * numFeat))+[-1] ].reset_index(drop=True)\n",
    "SVL10 = trainDataCur.iloc[SVindex, list(range(sindexSVMDATA + 6 * numFeat,sindexSVMDATA + 7 * numFeat))+[-1] ].reset_index(drop=True)\n",
    "SVL11 = trainDataCur.iloc[SVindex, list(range(sindexSVMDATA + 7 * numFeat,sindexSVMDATA + 8 * numFeat))+[-1] ].reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Bind original SV with modified to new train data set\n",
    "SVinvar = pd.concat([SVtotal, SVL2, SVL3, SVL5, SVL6, SVL7, SVL8, SVL9, SVL10, SVL11],ignore_index=True)\n",
    "\n",
    "# Split for training to feature and label\n",
    "trainFeatVSVM = SVinvar.iloc[:, :-1].reset_index(drop=True)\n",
    "trainLabelsVSVM = SVinvar.iloc[:, -1]\n",
    "\n",
    "# Get list with index of train data to split between train and test in svmFit\n",
    "countTrainData = SVinvar.shape[0]\n",
    "indexTrainData = [list(range(1, countTrainData + 1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainLabelsVSVM.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainFeatVSVM.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tuneFeatVSVM.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tuneFeatVSVM.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8049789543475848\n"
     ]
    }
   ],
   "source": [
    "# Join of train and test test data (through indexTrainData in svmFit separable)\n",
    "tuneFeatVSVM = pd.concat([trainFeatVSVM, testFeatsub])\n",
    "tuneLabelsVSVM = np.concatenate((trainLabelsVSVM.values, testLabels.values))\n",
    "\n",
    "# VSVM parameter tuning\n",
    "tunedVSVM = svm_fit(tuneFeatVSVM, tuneLabelsVSVM)\n",
    "\n",
    "# Run classification and accuracy assessment for modified SV\n",
    "predLabelsVSVM = tunedVSVM.predict(validateFeatsub)\n",
    "accVSVM = accuracy_score(validateLabels, predLabelsVSVM)\n",
    "print(accVSVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.merge(trainFeatVSVM, testFeatsub, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainFeatVSVM[0:10].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testFeatsub[0:10].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.concat([SVtotal,SVL2,SVL5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Iteration over bound to test different bound thresholds determining the radius of acceptance\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m jj \u001b[38;5;129;01min\u001b[39;00m bound:\n\u001b[0;32m      7\u001b[0m     SVinvarRadi \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([\n\u001b[1;32m----> 8\u001b[0m     \u001b[43mrem_extrem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSVtotal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSVL2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjj\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mset_axis(objInfoNames, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m      9\u001b[0m     rem_extrem(SVtotal, SVL3, jj)\u001b[38;5;241m.\u001b[39mset_axis(objInfoNames, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m     10\u001b[0m     rem_extrem(SVtotal, SVL5, jj)\u001b[38;5;241m.\u001b[39mset_axis(objInfoNames, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m     11\u001b[0m     rem_extrem(SVtotal, SVL6, jj)\u001b[38;5;241m.\u001b[39mset_axis(objInfoNames, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m     12\u001b[0m     rem_extrem(SVtotal, SVL7, jj)\u001b[38;5;241m.\u001b[39mset_axis(objInfoNames, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m     13\u001b[0m     rem_extrem(SVtotal, SVL8, jj)\u001b[38;5;241m.\u001b[39mset_axis(objInfoNames, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m     14\u001b[0m     rem_extrem(SVtotal, SVL9, jj)\u001b[38;5;241m.\u001b[39mset_axis(objInfoNames, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m     15\u001b[0m     rem_extrem(SVtotal, SVL10, jj)\u001b[38;5;241m.\u001b[39mset_axis(objInfoNames, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m     16\u001b[0m     rem_extrem(SVtotal, SVL11, jj)\u001b[38;5;241m.\u001b[39mset_axis(objInfoNames, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;66;03m# rem_extrem(SVtotal, SVL12, bound[jj]).set_axis(objInfoNames, axis=1),\u001b[39;00m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;66;03m# rem_extrem(SVtotal, SVL13, bound[jj]).set_axis(objInfoNames, axis=1)\u001b[39;00m\n\u001b[0;32m     19\u001b[0m     ])    \n\u001b[0;32m     20\u001b[0m     \u001b[38;5;66;03m# Iterating over boundMargin to test different thresholds on margin distance\u001b[39;00m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m kk, bound_margin_val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(boundMargin):\n",
      "Cell \u001b[1;32mIn[4], line 19\u001b[0m, in \u001b[0;36mrem_extrem\u001b[1;34m(org, VSV1, a)\u001b[0m\n\u001b[0;32m     16\u001b[0m     distance\u001b[38;5;241m.\u001b[39mloc[l, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdistance\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m euc_dis(org\u001b[38;5;241m.\u001b[39miloc[l, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], VSV1\u001b[38;5;241m.\u001b[39miloc[l, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     18\u001b[0m SVClass1 \u001b[38;5;241m=\u001b[39m org[org[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mREF\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m org[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mREF\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique()[\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m---> 19\u001b[0m SVClass2 \u001b[38;5;241m=\u001b[39m org[org[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mREF\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[43morg\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mREF\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m]\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(SVClass1) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(SVClass1) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Utente\\mambaforge\\envs\\advpy\\lib\\site-packages\\pandas\\core\\arrays\\_mixins.py:289\u001b[0m, in \u001b[0;36mNDArrayBackedExtensionArray.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\n\u001b[0;32m    284\u001b[0m     \u001b[38;5;28mself\u001b[39m: NDArrayBackedExtensionArrayT,\n\u001b[0;32m    285\u001b[0m     key: PositionalIndexer2D,\n\u001b[0;32m    286\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NDArrayBackedExtensionArrayT \u001b[38;5;241m|\u001b[39m Any:\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mis_integer(key):\n\u001b[0;32m    288\u001b[0m         \u001b[38;5;66;03m# fast-path\u001b[39;00m\n\u001b[1;32m--> 289\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ndarray\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    290\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    291\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_box_func(result)\n",
      "\u001b[1;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "# VSVM - EVALUATION of all Level VSV\n",
    "actKappa = 0\n",
    "bestFittingModel = None\n",
    "\n",
    "# Iteration over bound to test different bound thresholds determining the radius of acceptance\n",
    "for jj in bound:\n",
    "    SVinvarRadi = pd.concat([\n",
    "    rem_extrem(SVtotal, SVL2, jj).set_axis(objInfoNames, axis=1),\n",
    "    rem_extrem(SVtotal, SVL3, jj).set_axis(objInfoNames, axis=1),\n",
    "    rem_extrem(SVtotal, SVL5, jj).set_axis(objInfoNames, axis=1),\n",
    "    rem_extrem(SVtotal, SVL6, jj).set_axis(objInfoNames, axis=1),\n",
    "    rem_extrem(SVtotal, SVL7, jj).set_axis(objInfoNames, axis=1),\n",
    "    rem_extrem(SVtotal, SVL8, jj).set_axis(objInfoNames, axis=1),\n",
    "    rem_extrem(SVtotal, SVL9, jj).set_axis(objInfoNames, axis=1),\n",
    "    rem_extrem(SVtotal, SVL10, jj).set_axis(objInfoNames, axis=1),\n",
    "    rem_extrem(SVtotal, SVL11, jj).set_axis(objInfoNames, axis=1),\n",
    "    # rem_extrem(SVtotal, SVL12, bound[jj]).set_axis(objInfoNames, axis=1),\n",
    "    # rem_extrem(SVtotal, SVL13, bound[jj]).set_axis(objInfoNames, axis=1)\n",
    "    ])    \n",
    "    # Iterating over boundMargin to test different thresholds on margin distance\n",
    "    for kk, bound_margin_val in enumerate(boundMargin):\n",
    "        SVinvar_list = []\n",
    "        \n",
    "        # Iterate over SVinvarRadi and evaluate distance to hyperplane\n",
    "        for m in range(len(SVinvarRadi)):\n",
    "            signa = pred_one(tunedVSVM, SVinvarRadi[m, :-1])\n",
    "            if SVinvarRadi[m, -1] == levels(generalDataPool.REF)[0]:\n",
    "                if -bound_margin_val < signa < bound_margin_val:\n",
    "                    SVinvar_list.append(SVinvarRadi[m, :])\n",
    "            else:\n",
    "                if -bound_margin_val < signa < bound_margin_val:\n",
    "                    SVinvar_list.append(SVinvarRadi[m, :])\n",
    "\n",
    "        SVinvar = pd.DataFrame(SVinvar_list, columns=objInfoNames)\n",
    "        \n",
    "        # Merge elected VSV with original SV\n",
    "        SVinvar_org = pd.concat([SVtotal, SVinvar])\n",
    "\n",
    "        # Split for training to feature and label\n",
    "        trainFeatVSVM = SVinvar_org.iloc[:, :-1]\n",
    "        trainLabelsVSVM = SVinvar_org.iloc[:, -1]\n",
    "\n",
    "        # Get list with index of trainData to split between train and test in svmFit\n",
    "        countTrainData = SVinvar_org.shape[0]\n",
    "        indexTrainData = [list(range(1, countTrainData + 1))]\n",
    "\n",
    "        # Join of train and test data (through indexTrainData in svmFit separable)\n",
    "        names = objInfoNames[:-1]\n",
    "        tuneFeatVSVM = pd.concat([trainFeatVSVM, testFeatsub], axis=0)\n",
    "        tuneFeatVSVM.columns = names\n",
    "        tuneLabelsVSVM = np.concatenate((trainLabelsVSVM.values, testLabels.values))\n",
    "\n",
    "        ######################################## VSVM control parameter tuning ########################################\n",
    "        tunedVSVM = SVC(kernel='linear')\n",
    "        tunedVSVM.fit(tuneFeatVSVM, tuneLabelsVSVM)\n",
    "\n",
    "        # Get the best fitting model based on Kappa\n",
    "        if actKappa < tunedVSVM.resample.Kappa:\n",
    "            bestFittingModel = tunedVSVM\n",
    "            actKappa = tunedVSVM.resample.Kappa\n",
    "\n",
    "# Run classification and accuracy assessment for the best bound setting\n",
    "# Predict labels of test data\n",
    "predLabelsVSVMsum = bestFittingModel.predict(validateFeatsub)\n",
    "\n",
    "# Accuracy assessment\n",
    "accVSVM_SL = accuracy_score(validateLabels, predLabelsVSVMsum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Balanced & Random unlabeled samples\n",
    "# Balanced samples\n",
    "\n",
    "# Definition of sampling configuration (strata: random sampling without replacement)\n",
    "stratSampRemaining_b = resample(trainDataCurRemaining, n_samples=[b, b, b, b, b, b], replace=False)\n",
    "samplesRemaining_b = trainDataCurRemaining.iloc[stratSampRemaining_b]\n",
    "\n",
    "trainDataCurRemaining_b = samplesRemaining_b.iloc[:, :-1]\n",
    "trainDataCurRemainingsub_b = trainDataCurRemaining_b.iloc[:, sindexSVMDATA:eindexSVMDATA]\n",
    "REF_b = bestFittingModel.predict(trainDataCurRemainingsub_b)\n",
    "\n",
    "SVindexUn_b = np.arange(1, len(trainDataCurRemainingsub_b) + 1)\n",
    "SVtotalUn_b = trainDataCurRemaining_b.iloc[SVindexUn_b - 1, sindexSVMDATA:eindexSVMDATA]\n",
    "SVtotalUn_b['REF'] = REF_b\n",
    "\n",
    "SVL2Un_b = trainDataCurRemaining.iloc[SVindexUn_b - 1, sindexSVMDATA - 2*numFeat:sindexSVMDATA - numFeat - 1].copy()\n",
    "SVL2Un_b['REF'] = REF_b\n",
    "SVL3Un_b = trainDataCurRemaining.iloc[SVindexUn_b - 1, sindexSVMDATA - numFeat:sindexSVMDATA - 1].copy()\n",
    "SVL3Un_b['REF'] = REF_b\n",
    "SVL5Un_b = trainDataCurRemaining_b.iloc[SVindexUn_b - 1, sindexSVMDATA + numFeat:sindexSVMDATA + 2*numFeat - 1].copy()\n",
    "SVL5Un_b['REF'] = REF_b\n",
    "SVL6Un_b = trainDataCurRemaining_b.iloc[SVindexUn_b - 1, sindexSVMDATA + 2*numFeat:sindexSVMDATA + 3*numFeat - 1].copy()\n",
    "SVL6Un_b['REF'] = REF_b\n",
    "SVL7Un_b = trainDataCurRemaining_b.iloc[SVindexUn_b - 1, sindexSVMDATA + 3*numFeat:sindexSVMDATA + 4*numFeat - 1].copy()\n",
    "SVL7Un_b['REF'] = REF_b\n",
    "SVL8Un_b = trainDataCurRemaining_b.iloc[SVindexUn_b - 1, sindexSVMDATA + 4*numFeat:sindexSVMDATA + 5*numFeat - 1].copy()\n",
    "SVL8Un_b['REF'] = REF_b\n",
    "SVL9Un_b = trainDataCurRemaining_b.iloc[SVindexUn_b - 1, sindexSVMDATA + 5*numFeat:sindexSVMDATA + 6*numFeat - 1].copy()\n",
    "SVL9Un_b['REF'] = REF_b\n",
    "SVL10Un_b = trainDataCurRemaining_b.iloc[SVindexUn_b - 1, sindexSVMDATA + 6*numFeat:sindexSVMDATA + 7*numFeat - 1].copy()\n",
    "SVL10Un_b['REF'] = REF_b\n",
    "SVL11Un_b = trainDataCurRemaining_b.iloc[SVindexUn_b - 1, sindexSVMDATA + 7*numFeat:sindexSVMDATA + 8*numFeat - 1].copy()\n",
    "SVL11Un_b['REF'] = REF_b\n",
    "\n",
    "SVinvarUn_b = pd.concat([SVtotalUn_b, SVL2Un_b, SVL3Un_b, SVL5Un_b, SVL6Un_b, SVL7Un_b, SVL8Un_b, SVL9Un_b, SVL10Un_b, SVL11Un_b])\n",
    "\n",
    "# Balanced Unlabeled samples\n",
    "\n",
    "actKappa = 0\n",
    "\n",
    "for jj in range(len(bound)):\n",
    "    SVinvarRadiUn_b_list = []\n",
    "    for m in range(len(SVinvarRadiUn_b)):\n",
    "        signa = pred_one(tunedSVM.finalModel, SVinvarRadiUn_b.iloc[m, :-1])\n",
    "        if SVinvarRadiUn_b.iloc[m, -1] == levels(generalDataPool.REF)[0]:\n",
    "            if -bound_margin_val < signa < bound_margin_val:\n",
    "                SVinvarRadiUn_b_list.append(SVinvarRadiUn_b.iloc[m, :])\n",
    "        else:\n",
    "            if -bound_margin_val < signa < bound_margin_val:\n",
    "                SVinvarRadiUn_b_list.append(SVinvarRadiUn_b.iloc[m, :])\n",
    "\n",
    "    SVinvarUn_b = pd.DataFrame(SVinvarRadiUn_b_list, columns=objInfoNames)\n",
    "    \n",
    "    SVinvar_orgUn_b = pd.concat([SVtotal, SVinvarUn_b])\n",
    "\n",
    "    trainFeatVSVMUn_b = SVinvar_orgUn_b.iloc[:, :-1]\n",
    "    trainLabelsVSVMUn_b = SVinvar_orgUn_b.iloc[:, -1]\n",
    "\n",
    "    countTrainDataUn_b = SVinvar_orgUn_b.shape[0]\n",
    "    indexTrainDataUn_b = [list(range(1, countTrainDataUn_b + 1))]\n",
    "\n",
    "    names = objInfoNames[:-1]\n",
    "    tuneFeatVSVMUn_b = pd.concat([trainFeatVSVMUn_b, testFeatsub], axis=0)\n",
    "    tuneFeatVSVMUn_b.columns = names\n",
    "    tuneLabelsVSVMUn_b = np.concatenate((trainLabelsVSVMUn_b.values, testLabels.values))\n",
    "\n",
    "    tunedVSVMUn_b = SVC(kernel='linear')\n",
    "    tunedVSVMUn_b.fit(tuneFeatVSVMUn_b, tuneLabelsVSVMUn_b)\n",
    "\n",
    "    if actKappa < tunedVSVMUn_b.resample.Kappa:\n",
    "        bestFittingModelUn_b = tunedVSVMUn_b\n",
    "        actKappa = tunedVSVMUn_b.resample.Kappa\n",
    "\n",
    "# Run classification and accuracy assessment for the best bound setting\n",
    "predLabelsVSVMsumUn_b = bestFittingModelUn_b.predict(validateFeatsub)\n",
    "\n",
    "# Accuracy assessment\n",
    "accVSVM_SL_Un_b = accuracy_score(validateLabels, predLabelsVSVMsumUn_b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predicted labels to the features data set\n",
    "predLabelsVSVMsumUn_unc = pd.concat([validateFeatsub, pd.DataFrame(predLabelsVSVMsumUn_b, columns=[\"Predicted_Labels\"])], axis=1)\n",
    "predLabelsVSVMsumUn_unc.columns = objInfoNames\n",
    "\n",
    "# Calculate uncertainty of the samples by selecting SV's and data set\n",
    "normdistvsvm_sl_un = uncertainty_dist_v2_2(bestFittingModelUn_b, predLabelsVSVMsumUn_unc)\n",
    "\n",
    "# Alter labels\n",
    "predlabels_vsvm_Slu = alter_labels(normdistvsvm_sl_un, validateLabels)\n",
    "\n",
    "# Accuracy assessment\n",
    "accVSVM_SL_Un_b_ad = accuracy_score(validateLabels, predlabels_vsvm_Slu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "advpy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
