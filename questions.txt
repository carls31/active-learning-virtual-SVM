 1.  DONE try without indexTrain  
 2.  DONE perform PCA for visualization and clustering
 3.  DONE split alter_samples in multiple iterations 
 4.  DONE check if in the multiclas setting the random / balanced unlabeled samples actually change
 5.  DONE implement only_probability_distance + check different implementation of mclu (see paper) 
 6.  DONE check if NDVI feature is actually useful
 7.  DONE boundClass1 PROBLEM related to sample_size = 1 or to implementation error -> check values inside variables
 8.  DONE implement binary + multiclass in the same script
 9.  DONE tune alter_label hyperparameter: how many label need to be relabeled?
 10. DONE overall hyperparameters optimization e.g. "boundMargin" and "bound" 
 11. DONE descriptive stats of the dataset/data visualization
 12. DONE Kappa-score coefficient definition: change the metric from "kappa" to "ROC" (and maybe also to "accuracy") 
 13. FUTURE -> check why if(!tmp_cond){VSV1[k,]=NA} in rem_extrem_kerneldist doesn't work
 14. FUTURE -> one vs all VSM Classification instead of binarymulticlass
 15. DONE why multiclass script is implemented differently from the binary ones and got different accuracies
 16. DONE add a flag to see which label actually changed
 17. DONE add shape scripts
 18. DONE add hadagera scripts
 19. DONE check if it is sufficient to run registerDoParallel(num_cores) just once inside the script
 20. DONE either balanced the datapool at the beginning or the each train/test/validate/unlabeled set
 21. DONE pick one new sample at time OR pick multiple from different regions/classes
 22. DONE plots for different model accuracies with different training data size and unlabeled samples
 23. FUTURE -> IMPLEMENT ksvm 
 24. DONE implement VSVM-SL + VIRTUAL Unlabeled Samples on new_tunedVSVM IT
 25. DONE use the kernel_function from the base_svm 
 26. normalized_data -> only for visualization purposes (eg thematic map in qgis)
 27. DONE compare ud accuracies with and without clustering
 28. with few initial samples, check how many samples actually are present when we train each model
 29. DONE compare VSVM / VSVM_SL / VSVM_SL Unl / VSVM_SL V Unl as base model for ITerative AL and especially VSVM_SL Unl
 30. DONE check why SVM as an Accuracy of 90% just with 3 samples
 31. DONE check sampleSize = sampleSizePor[sample_size] - sampleSizePor[sample_size-1]
 32. DONE compare VSVM_SL_Un_it trained on SVM/VSVM with VSVM_SL_Un_b/VSVM_SL_vUn_b
 33. DONE compare acc from VSVM_SL_Un_it trained before and after VSVM_SL_vUn_b vs VSVM_SL_vUn_b trained before and after VSVM_SL_Un_it
 34. DONE check the amount of nan values in hagadera 
 35. DONE check the VSVM / VSVM_SL / VSVM_SL_Un performance on the orginal
 36. DONE try MS with one sample per iteration
 37. FUTURE -> IMPLEMENT MS-cSV 
 38. DONE collect accuracy results from different realization but same hyperparameters setup
 39. DONE consider all the levels for the uncertainty distance 
 40. DONE check which VSVM_SL_vUn_b work better between the to possible implementations 
 41. DONE check warnings in AL binary hagadera -> na due to ncol(samplesRemaining) in UNCERTAINTY DISTANCE FUNCTIONS
 42. DONE check if running tmp_pred = predict(tmp_new_tunedVSVM, validateFeatsub) AND tmp_acc  = confusionMatrix(tmp_pred, validateLabels) the accVSVM_SL_itAL CHANGE OR NOT
 43. DONE update performance
 44. DONE check if using valid acc instead of test kappa increase performance 
 45. FUTURE -> BAYESIAN OPTIMIZATION FOR HYPERPARAMETERS TUNING  
 46. FUTURE -> try resampledSize proportional to sampleSizePor -> HYPERPARAMETER
 47. DONE check distance from the margin only for samples from the wrong side of the hyperplane
 48. DONE check the number of training samples before and after AL iterations -> col+hag MULTICLASS SHAPE
 49. DONE check SVM+AL again
 50. DONE -> IMPLEMENT t-SNE CLUSTERING  
 51. DONE progressive AL hyperparameters wrt sampleSizePor
 52. DONE AL on VSVs from SL
 53. DONE check for strange behaviour in the accuracies results: SVM multilevel, (e.g. general upside-down of the accuracy of the model [some go up while the others go down] -> biased set)
 54. FUTURE -> CNN
 55. DONE fix warnings AL_VSVM+SL
 56. build function for full AL procedure
 57. DONE check train test validate sample transformation in the whole pipeline -> DO NOT TRAIN MODEL ON ALREADY SEEN DATA
 58. DONE check low VSVM_SL accuracy sampleSizePor[1/9] -> due to poor initial train data set spread? (then it gets better) -> not really solved
 59. DONE boundMargin self_learn after AL is redundant since the samples we got are already the smallest -> just keep boundMargin=c(1)
 60. implement variant with clustering for each class 
 61. implement: new train_size -> old train_size + new_train_size VS new train_size_AL -> old train_size_AL + 2/class AL_samples + remaining new_train_size
 62. FUTURE -> change policy for active labeling (consider also the numberr of duplicates)
 63. limitation of the poolsize

CHECK THE VALUES INSIDE THE COMPUTED VECTORS

Lu et al.(2016): A Novel Synergetic Classification Approach for  Hyperspectral and Panchromatic Images Based on Self-Learning

DONE Inside svm package, check the difference between probability class and distance class -> see both related papers and script function
DONE check how many CPU cores are present on the RSRG server and how to use them
DONE vectorize: apply() {R function} + predict() {kernlab function} for performance efficency improvement

********************************************************

 
