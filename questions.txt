row 36  trainControl -> how does actually work with the indexTrain
row 197 rbf_kernel -> that I added is required, right?
row 371 abs(pred) -> for the distance we need only positive values, right? (I added abs)
row 603 ref_added_or[1:250,]$distance = 1 -> which are the actual values for the distance? after norm, the max value 1
row 956 binaryClassProblem -> compare every couple of class labels 

DONE Inside svm package, the difference between probability class and distance class -> see both related papers and script function

DONE USE BINARY CLASIFFICATION TO TEST THE SCRIPT 
CHECK THE VALUES INSIDE THE COMPUTED VECTORS

Lu et al.(2016): A Novel Synergetic Classification Approach for  Hyperspectral and Panchromatic Images Based on Self-Learning

improve performance efficency:
DONE check how many CPU cores are present on the RSRG server and how to use them
DONE vectorize: apply() {R function} + predict() {kernlab function} 

********************************************************


 1.  DONE try without indexTrain  
 2.  DONE perform PCA for visualization and clustering
 3.  DONE split alter_samples in multiple iterations 
 4.  DONE check if in the multiclas setting the random / balanced unlabeled samples actually change
 5.  DONE implement only_probability_distance + check different implementation of mclu (see paper) 
 6.  DONE check if NDVI feature is actually useful
 7.  DONE boundClass1 PROBLEM related to sample_size = 1 or to implementation error -> check values inside variables
 8.  DONE implement binary + multiclass in the same script
 9.  DONE tune alter_label hyperparameter: how many label need to be relabeled?
 10. DONE overall hyperparameters optimization e.g. "boundMargin" and "bound" 
 11. DONE descriptive stats of the dataset/data visualization
 12. DONE Kappa-score coefficient definition: change the metric from "kappa" to "ROC" (and maybe also to "accuracy") 
 13. FUTURE -> check why if(!tmp_cond){VSV1[k,]=NA} in rem_extrem_kerneldist doesn't work
 14. FUTURE -> one vs all VSM Classification instead of binarymulticlass
 15. DONE why multiclass script is implemented differently from the binary ones and got different accuracies
 16. DONE add a flag to see which label actually changed
 17. DONE add shape scripts
 18. DONE add hadagera scripts
 19. DONE check if it is sufficient to run registerDoParallel(num_cores) just once inside the script
 20. DONE either balanced the datapool at the beginning or the each train/test/validate/unlabeled set
 21. DONE pick one new sample at time OR pick multiple from different regions/classes
 22. DONE plots for different model accuracies with different training data size and unlabeled samples
 23. FUTURE -> IMPLEMENT ksvm 
 24. DONE implement VSVM-SL + VIRTUAL Unlabeled Samples on new_tunedVSVM IT
 25. DONE use the kernel_function from the base_svm 
 26. normalized_data -> only for visualization purposes (eg thematic map in qgis)
 27. DONE compare ud accuracies with and without clustering
 28. with few initial samples, check how many samples actually are present when we train each model
 29. DONE compare VSVM / VSVM_SL / VSVM_SL Unl / VSVM_SL V Unl as base model for ITerative AL and especially VSVM_SL Unl
 30. DONE check why SVM as an Accuracy of 90% just with 3 samples
 31. DONE check sampleSize = sampleSizePor[sample_size] - sampleSizePor[sample_size-1]
 32. DONE compare VSVM_SL_Un_it trained on SVM/VSVM with VSVM_SL_Un_b/VSVM_SL_vUn_b
 33. DONE compare acc from VSVM_SL_Un_it trained before and after VSVM_SL_vUn_b vs VSVM_SL_vUn_b trained before and after VSVM_SL_Un_it
 34. DONE check the amount of nan values in hagadera 
 35. DONE check the VSVM / VSVM_SL / VSVM_SL_Un performance on the orginal
 36. DONE try MS with one sample per iteration
 37. FUTURE -> IMPLEMENT MS-cSV 
 38. DONE collect accuracy results from different realization but same hyperparameters setup
 39. DONE consider all the levels for the uncertainty distance 
 40. DONE check which VSVM_SL_vUn_b work better between the to possible implementations 
 41. DONE check warnings in AL binary hagadera -> na due to ncol(samplesRemaining) in UNCERTAINTY DISTANCE FUNCTIONS
 42. DONE check if running tmp_pred = predict(tmp_new_tunedVSVM, validateFeatsub) AND tmp_acc  = confusionMatrix(tmp_pred, validateLabels) the accVSVM_SL_itAL CHANGE OR NOT
 43. DONE update performance
 44. DONE check if using valid acc instead of test kappa increase performance 
 45. FUTURE -> BAYESIAN OPTIMIZATION FOR HYPERPARAMETERS TUNING  
 46. FUTURE -> try resampledSize proportional to sampleSizePor -> HYPERPARAMETER
 47. check distance from the margin only for samples from the wrong side of the hyperplane
 48. check the number of training samples before and after AL iterations -> col+hag MULTICLASS SHAPE
 49. check SVM+AL again
 50. FUTURE -> IMPLEMENT t-SNE CLUSTERING  
 51. DONE progressive AL hyperparameters wrt sampleSizePor
 52. DONE AL on VSVs from SL
 53. check for strange behaviour in the accuracies results: SVM multilevel, (e.g. general upside-down of the accuracy of the model [some go up while the others go down] -> biased set)
 54. FUTURE -> CNN

cologne multiclass shape

cologne multiclass-binary shape-scale
hagadera multiclass-binary shape-scale


pseudo code + flowchart of VSVM SL vUN (?) [maybe to be added in the benchmark instead?]
	           AL VSVM SL 1
	           AL VSVM SL 2
	           AL VSVM SL 3
benchmark with Random AL VSVM SL 
	           AL VSVM SL 
	           AL SL VSVM SL  -  how
		   AL VSVM SL + SEMI  -  how
add semi-labeled samples after each iteration of AL
  
